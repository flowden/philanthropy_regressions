{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cda3a240",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/finnianlowden/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import csv\n",
    "import nltk\n",
    "import statistics\n",
    "from nltk.corpus import stopwords # Importing stop words (e.g., the, and, a, of, etc.)\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1996bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data dictionaries\n",
    "\n",
    "\n",
    "# donations_df data dictionary\n",
    "# Variable                    Type       Description\n",
    "# Grantmaker_name             String     Corporation/foundation that gave grant\n",
    "# Year                        Int        Year grant was given\n",
    "# Recipient_name              String     Organization that recived grant\n",
    "# NTEE_code                   String     NTEE code of organization given grant\n",
    "# NTEE_category               String     Broader category of organization according to IRS\n",
    "# Grant Amount                Float      Grant amount adjusted for inflation to 2020 dollars\n",
    "# Recipient_city              String     City of recipient organization\n",
    "# Recipient_state             String     State of recipient organization\n",
    "\n",
    "\n",
    "# text_df data dictionary\n",
    "# Variable                    Type       Description\n",
    "# Group                       String     Name of environmental nonprofit\n",
    "# Individualism               Float      Measure of prevalence of this discourse of delay (DoD) in the text\n",
    "# The 'free rider' excuse     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Whataboutism                Float      Measure of prevalence of this DoD in the text in given year\n",
    "# All talk, little action     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Fossil fuel solutionism     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# No sticks, just carrots     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Technological optimism      Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Appeal to well-being        Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Policy perfectionism        Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Appeal to social justice    Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Change is impossible        Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Doomism                     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Year                        Int        Year associated with prevalence measure\n",
    "# AF_indc                     Int        Indicator variable for American Forests (AF)\n",
    "# NFWF_indc                   Int        Indicator variable for the National Fish and Wildlife Foundation (NFWF)\n",
    "# NRDC_indc                   Int        Indicator variable for the Natural Resources Defense Council (NRDC)\n",
    "# CI_indc                     Int        Indicator variable for Conservation International(CI)\n",
    "# WWF_indc                    Int        Indicator variable for the World Wildlife Fund (WWF)\n",
    "# SC_indc                     Int        Indicator variable for the Sierra Club (SC)\n",
    "# OC_indc                     Int        Indicator variable for The Ocean Conservancy (OC)\n",
    "# EDF_indc                    Int        Indicator variable for the Environmental Defense Fund (EDF)\n",
    "# NAS_indc                    Int        Indicator variable for the National Audubon Society (NAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13cd86ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing data\n",
    "\n",
    "# (1)\n",
    "# Corporate giving dataset - local\n",
    "complete_donations_df = pd.read_excel(\"Oil_corporations_NTEE_Data_MASTER_SHEET.xlsx\", sheet_name = \"Individual_donations\")\n",
    "\n",
    "# (2)\n",
    "# Text data\n",
    "# Adding experiment text data - online\n",
    "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1Zr4SQFxq8u3FnQwRyIHCoQ1Az_lb1PXd45Dhkni7Uok/edit#gid=570879331\"\n",
    "spreadsheet_url = spreadsheet_url.replace(\"/edit#gid=\", \"/export?format=csv&gid=\") # Online\n",
    "experiment_text_df = pd.read_csv(spreadsheet_url, header=0) # Online\n",
    "# Adding control text data\n",
    "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1Zr4SQFxq8u3FnQwRyIHCoQ1Az_lb1PXd45Dhkni7Uok/edit#gid=1393581184\"\n",
    "spreadsheet_url = spreadsheet_url.replace(\"/edit#gid=\", \"/export?format=csv&gid=\") # Online\n",
    "control_text_df = pd.read_csv(spreadsheet_url, header=0) # Online\n",
    "# Joining control and experiment\n",
    "complete_text_df = pd.concat([experiment_text_df, control_text_df])\n",
    "\n",
    "# (3)\n",
    "# Discourses of Delay - online\n",
    "spreadsheet_url = \"https://docs.google.com/spreadsheets/d/1MhB60vzde7KT9Ti6eQtimmWvYAEersI4zK3L_gwDNA8/edit#gid=0\"\n",
    "spreadsheet_url = spreadsheet_url.replace(\"/edit#gid=\", \"/export?format=csv&gid=\")\n",
    "\n",
    "delay_df = pd.read_csv(spreadsheet_url, header=0)\n",
    "\n",
    "simple_delay_names = {\"Individualism\": \"Individualism\", \"Whataboutism\":\n",
    "             \"Whataboutism\", \"Doomism\": \"Doomism\",\n",
    "             \"The 'free rider' excuse\": 'Free_rider',\n",
    "             \"All talk, little action\": 'Talk_no_action',\n",
    "             \"Fossil fuel solutionism\": 'FF_solutionism',\n",
    "             \"No sticks, just carrots\": 'Carrots',\n",
    "             \"Technological optimism\": 'Tech_optimism',\n",
    "             \"Appeal to well-being\": 'Well_being',\n",
    "             \"Policy perfectionism\": 'Perfect_policy',\n",
    "             \"Appeal to social justice\": 'Social_justice',\n",
    "             \"Change is impossible\": 'Change_impossible'}\n",
    "\n",
    "complete_discourse_dict = {}\n",
    "for row in delay_df.iterrows():\n",
    "    delay_method = row[1][\"Sub-category\"]\n",
    "    dict_words = row[1][\"Current_dict\"].split(\", \")\n",
    "    complete_discourse_dict[simple_delay_names[delay_method]] = dict_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b02c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Formatting dataframes\n",
    "\n",
    "# Working with corporate philanthropy data\n",
    "# Dropping irrelevant columns (those not in data dictionary)\n",
    "donations_df = complete_donations_df[[\"grantmaker_name\", \"year\", \"recipient_name\", \"NTEE_code\",\n",
    "                                      \"NTEE_category\", \"Grant Amount (2020 Dollars)\",\n",
    "                                      \"recipient_city\", \"recipient_state\"]]\n",
    "\n",
    "# Renaming Grant Amount (2020 Dollars) to not include spaces & converting to int\n",
    "donations_df = donations_df.rename(columns = {\"Grant Amount (2020 Dollars)\": \"grant_amount\"})\n",
    "donations_df[\"grant_amount\"] = donations_df[\"grant_amount\"]\n",
    "\n",
    "# Making copy of complete_text_df\n",
    "text_df = complete_text_df.copy()\n",
    "text_df.drop(columns={'Researcher'}, inplace = True)\n",
    "\n",
    "# Making copy of complete_text_df\n",
    "discourse_dict = complete_discourse_dict.copy()\n",
    "\n",
    "# Checking to make sure changes were made\n",
    "# donations_df.head()\n",
    "# text_df.head()\n",
    "# discourse_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d2ec1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data wrangling\n",
    "\n",
    "# (1)\n",
    "# Text cleaning\n",
    "# Importing punctuation and stopwords\n",
    "stopWords = set(stopwords.words('english'))\n",
    "table_punctuation = str.maketrans('', '', '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~â€™') \n",
    "\n",
    "# Cleaning text data\n",
    "textCleaned = [] # Creating an empty list to store list of cleaned words\n",
    "for row in text_df[\"Document_text\"]: # Looping through each Tweet in ukraineRussia_df\n",
    "    rowCleaned = [] # Creating an empty list to store cleaned words from each Tweet\n",
    "    row_as_list = str(row).split() # Splitting row into a list of words at ' '\n",
    "    for word in row_as_list: # Looping through each word in row_as_list\n",
    "        if word not in stopWords and word != \"nan\":\n",
    "            text = word.translate(table_punctuation) # Translating punctuation into ''\n",
    "            textLower = text.lower() # Converting text to lowercase\n",
    "            rowCleaned.append(textLower) # Appending cleaned word to rowCleaned list\n",
    "    textCleaned.append(rowCleaned)  # Appending rowCleaned to textCleaned list\n",
    "\n",
    "text_df[\"cleaned_text\"] = textCleaned\n",
    "\n",
    "\n",
    "# (2)\n",
    "# Creating document-term matrix\n",
    "# Getting list of Discourses of Delay\n",
    "best_dicts = [\"FF_solutionism\", \"Well_being\", \"Social_justice\", \"Carrots\"]\n",
    "top6_dicts = [\"FF_solutionism\", \"Well_being\", \"Social_justice\", \"Carrots\", \"Free_rider\", \"Whataboutism\"]\n",
    "all_dicts = list(discourse_dict)\n",
    "delay_types = all_dicts\n",
    "\n",
    "# Getting all words in DoD dictionaries\n",
    "delay_vocabulary = set()\n",
    "for delay in delay_types:\n",
    "    delay_vocabulary.update(discourse_dict[delay])\n",
    "    \n",
    "regression_df = text_df.copy()\n",
    "    \n",
    "\n",
    "# Creating DoD_results dict\n",
    "DoD_results = {}\n",
    "    \n",
    "for col in delay_vocabulary:\n",
    "    wordAppearance = []\n",
    "    for text in text_df[\"cleaned_text\"]:\n",
    "        mySum = 0\n",
    "        prevWord = \"\"\n",
    "        for word in text:\n",
    "            if word == col:\n",
    "                mySum += 1\n",
    "            bigram = prevWord + \" \" + word\n",
    "            if bigram == col:\n",
    "                mySum += 1\n",
    "            # Creating DoD results dict\n",
    "            if word == col or bigram == col:\n",
    "                for delay in discourse_dict:\n",
    "                    og_words = [x.lower() for x in discourse_dict[delay]]\n",
    "                    if word in og_words:                \n",
    "                        if delay not in set(DoD_results):\n",
    "                            DoD_results[delay] = {word}\n",
    "                        else:\n",
    "                            DoD_results[delay].add(word)\n",
    "                    if bigram in og_words:                \n",
    "                        if delay not in set(DoD_results):\n",
    "                            DoD_results[delay] = {bigram}\n",
    "                        else:\n",
    "                            DoD_results[delay].add(bigram)    \n",
    "            prevWord = word  \n",
    "        wordAppearance.append(mySum)\n",
    "    if (sum(wordAppearance) > 0):\n",
    "        regression_df[col] = wordAppearance\n",
    "\n",
    "# Creating dict of words with their associated dictionaries      \n",
    "word_to_DoD = {}\n",
    "for delay in DoD_results:\n",
    "    wordSet = DoD_results[delay]\n",
    "    for word in wordSet:\n",
    "        if word not in word_to_DoD:\n",
    "            word_to_DoD[word] = {delay}\n",
    "        else:\n",
    "            word_to_DoD[word].add(delay)\n",
    "\n",
    "# (3)\n",
    "# Adding donation information\n",
    "# Adding amount of donation in given year\n",
    "reduce_donations_df = donations_df.copy()\n",
    "group_list = ['nature conservancy', 'american forests', 'national fish and wildlife foundation',\n",
    " 'natural resources defense council', 'conservation international', 'world wildlife fund',\n",
    " 'sierra club', 'ocean conservancy', 'environmental defense fund', 'audubon society']\n",
    "reduce_donations_df[\"recipient_name\"] = reduce_donations_df[\"recipient_name\"].str.lower()\n",
    "boolean_series = reduce_donations_df[\"recipient_name\"].isin(group_list)\n",
    "reduce_donations_df = reduce_donations_df[boolean_series]\n",
    "\n",
    "# Grouping by year and group\n",
    "annualized_donations_df = reduce_donations_df.groupby(\n",
    "    ['recipient_name', 'year'], as_index = False).agg({'grant_amount': sum})\n",
    "annualized_donations_df = pd.DataFrame(annualized_donations_df)\n",
    "# annualized_donations_df.to_excel(\"Output.xlsx\", index = False) # code to download as XSLX\n",
    "\n",
    "# Adding donations to text_df\n",
    "annualized_donations_df = annualized_donations_df.rename(\n",
    "    columns = {\"recipient_name\": \"Organization_name\", \"year\": \"Document_year\"}) # Renaming group column\n",
    "regression_df[\"Organization_name\"] = regression_df[\"Organization_name\"].str.lower()\n",
    "# annualized_donations_df['Document_year'] += 2\n",
    "regression_df = pd.merge(regression_df, annualized_donations_df, on = ['Organization_name', 'Document_year'], how = 'outer')\n",
    "regression_df[\"grant_amount\"] = regression_df[\"grant_amount\"].fillna(0)\n",
    "\n",
    "# Adding indicator for recieving a donation\n",
    "regression_df['recieved_donation'] = np.where(regression_df['grant_amount'] > 0, 1, 0)\n",
    "\n",
    "# Helper function to link words with the DoD dicts they appear in\n",
    "def getDod(coef_df):\n",
    "    list_dicts = []\n",
    "    for word in coef_df[\"var\"]:\n",
    "        list_dicts.append(word_to_DoD[word])   \n",
    "    return list_dicts\n",
    "\n",
    "# Prints out each delay with words found in corpus vocabulary\n",
    "# for delay in DoD_results:\n",
    "#     print(delay, DoD_results[delay])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a35e3fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score predicting treatment w/ training data: 0.3270153002968714\n",
      "Accuracy score predicting treatment w/ testing data: 0.28858447488584477\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>val_logitlasso</th>\n",
       "      <th>DoD_Dicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hinder</td>\n",
       "      <td>-1.615984</td>\n",
       "      <td>{Social_justice}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>total emissions</td>\n",
       "      <td>-1.530355</td>\n",
       "      <td>{Whataboutism}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>regressive</td>\n",
       "      <td>-1.482302</td>\n",
       "      <td>{Social_justice}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>-1.323783</td>\n",
       "      <td>{Doomism}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>disruptive</td>\n",
       "      <td>-1.255040</td>\n",
       "      <td>{Well_being}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>consumer choice</td>\n",
       "      <td>4.102253</td>\n",
       "      <td>{Individualism}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>near future</td>\n",
       "      <td>4.180052</td>\n",
       "      <td>{Tech_optimism}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>low income</td>\n",
       "      <td>4.488508</td>\n",
       "      <td>{Social_justice}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>take advantage</td>\n",
       "      <td>4.587673</td>\n",
       "      <td>{Free_rider}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>sequestration</td>\n",
       "      <td>4.685180</td>\n",
       "      <td>{Tech_optimism}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                var  val_logitlasso         DoD_Dicts\n",
       "18           hinder       -1.615984  {Social_justice}\n",
       "23  total emissions       -1.530355    {Whataboutism}\n",
       "64       regressive       -1.482302  {Social_justice}\n",
       "20      uncertainty       -1.323783         {Doomism}\n",
       "10       disruptive       -1.255040      {Well_being}\n",
       "..              ...             ...               ...\n",
       "11  consumer choice        4.102253   {Individualism}\n",
       "49      near future        4.180052   {Tech_optimism}\n",
       "33       low income        4.488508  {Social_justice}\n",
       "13   take advantage        4.587673      {Free_rider}\n",
       "34    sequestration        4.685180   {Tech_optimism}\n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LogitLasso reg\n",
    "\n",
    "# Predicting treatment vs control\n",
    "# Creating data for regressions\n",
    "logit_df = regression_df.copy()\n",
    "regression_df.to_excel(\"regression_df.xlsx\")\n",
    "\n",
    "# Adding indicator for recieving a donation\n",
    "logit_df['experiment_group'] = np.where(\n",
    "    logit_df['Organization_name'].isin({\"greenpeace\", \"earthjustice\"}), 0, 1)\n",
    "\n",
    "# Dropping null values\n",
    "logit_df.dropna(inplace = True)\n",
    "\n",
    "# Exporting logit_df as xlsx\n",
    "logit_df.to_excel(\"logit_df.xlsx\")\n",
    "\n",
    "# Creating training and testing splits from logit_df\n",
    "y = logit_df['experiment_group']\n",
    "X = logit_df.drop(columns = [\"experiment_group\", \"recieved_donation\", \"grant_amount\", \"Organization_name\", \"Document_title\",\n",
    "                                  \"Document_type\", \"Reference\", \"Document_text\", \"Word_counts\",\n",
    "                                  \"cleaned_text\", \"Document_year\"])\n",
    "\n",
    "# Making sure all non-numeric columns and NaN values have been dropped\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "\n",
    "# Setting test size to 0.2 means that 80% of my data will be used to train and 20% will be used for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1680)\n",
    "\n",
    "### Logistic-LASSO Model\n",
    "logReg = LogisticRegressionCV(Cs = 20, cv = 10, penalty = 'l1', solver = 'liblinear',\n",
    "                              refit = True, class_weight = \"balanced\")\n",
    "logReg = logReg.fit(X_train, y_train)\n",
    "\n",
    "# Printing coefficient data\n",
    "coef1 = pd.DataFrame({'var':X.columns, 'val_logitlasso':logReg.coef_[0]})\n",
    "coef1.sort_values(by = ['val_logitlasso'], inplace = True)\n",
    "coef1[\"DoD_Dicts\"] = getDod(coef1)\n",
    "coef1.to_excel(\"logReg_coef_expGroup.xlsx\", index = False)\n",
    "\n",
    "# Predicted probability for text recieving donation\n",
    "print(\"Accuracy score predicting treatment w/ training data: \" + str(\n",
    "    accuracy_score(y_train, logReg.predict(X_train)))) # Prints accuracy score of y_train and Logit prediction of X_train\n",
    "print(\"Accuracy score predicting treatment w/ testing data: \" + str(\n",
    "    accuracy_score(y_test, logReg.predict(X_test)))) # Prints accuracy score of y_test and Logit prediction of X_train\n",
    "coef1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "979cd97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score predicting recieved_donation w/ training data: 0.5980817538250742\n",
      "Accuracy score predicting recieved_donation w/ testing data: 0.5972602739726027\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var</th>\n",
       "      <th>val_logitlasso</th>\n",
       "      <th>DoD_Dicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>invent</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Tech_optimism}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>prescribe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Carrots}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>appetite</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Whataboutism}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>unfair</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Social_justice}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>failure</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Change_impossible}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>uncertainty</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Doomism}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>vulnerable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Well_being}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>hinder</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Social_justice}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>inevitable</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Doomism}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>voluntary</td>\n",
       "      <td>0.0</td>\n",
       "      <td>{Carrots}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            var  val_logitlasso            DoD_Dicts\n",
       "0        invent             0.0      {Tech_optimism}\n",
       "36    prescribe             0.0            {Carrots}\n",
       "37     appetite             0.0       {Whataboutism}\n",
       "38       unfair             0.0     {Social_justice}\n",
       "39      failure             0.0  {Change_impossible}\n",
       "..          ...             ...                  ...\n",
       "20  uncertainty             0.0            {Doomism}\n",
       "19   vulnerable             0.0         {Well_being}\n",
       "18       hinder             0.0     {Social_justice}\n",
       "24   inevitable             0.0            {Doomism}\n",
       "68    voluntary             0.0            {Carrots}\n",
       "\n",
       "[69 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### LogitLasso reg\n",
    "\n",
    "# Predicting if money was recieved that year\n",
    "# Creating data for regressions\n",
    "logit_df = regression_df.copy()\n",
    "\n",
    "# Dropping null values\n",
    "logit_df.dropna(inplace = True)\n",
    "\n",
    "# Exporting regression_df as xlsx\n",
    "logit_df.to_excel(\"logit_df.xlsx\")\n",
    "\n",
    "# Creating training and testing splits from logit_df\n",
    "y = logit_df['recieved_donation']\n",
    "X = logit_df.drop(columns = [\"recieved_donation\", \"grant_amount\", \"Organization_name\", \"Document_title\",\n",
    "                                  \"Document_type\", \"Reference\", \"Document_text\", \"Word_counts\",\n",
    "                                  \"cleaned_text\", \"Document_year\"])\n",
    "\n",
    "# Making sure all non-numeric columns and NaN values have been dropped\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "\n",
    "# Setting test size to 0.2 means that 80% of my data will be used to train and 20% will be used for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1680)\n",
    "\n",
    "### Logistic-LASSO Model\n",
    "logReg = LogisticRegressionCV(Cs = 20, cv = 10, penalty = 'l1', solver = 'liblinear', refit = True)\n",
    "logReg = logReg.fit(X_train, y_train)\n",
    "\n",
    "# Printing coefficient data\n",
    "coef2 = pd.DataFrame({'var':X.columns, 'val_logitlasso':logReg.coef_[0]})\n",
    "coef2.sort_values(by = ['val_logitlasso'], inplace = True)\n",
    "coef2[\"DoD_Dicts\"] = getDod(coef2)\n",
    "coef2.to_excel(\"logReg_coef_gotMoneyYear.xlsx\", index = False)\n",
    "\n",
    "# Predicted probability for text recieving donation\n",
    "print(\"Accuracy score predicting recieved_donation w/ training data: \" + str(\n",
    "    accuracy_score(y_train, logReg.predict(X_train)))) # Prints accuracy score of y_train and Logit prediction of X_train\n",
    "print(\"Accuracy score predicting recieved_donation w/ testing data: \" + str(\n",
    "    accuracy_score(y_test, logReg.predict(X_test)))) # Prints accuracy score of y_test and Logit prediction of X_train\n",
    "coef2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32041a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
