{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452ee96c",
   "metadata": {},
   "source": [
    "# Philanthropy Regressions\n",
    "### Finnian Lowden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1424f37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Data dictionaries\n",
    "\n",
    "\n",
    "# donations_df data dictionary\n",
    "# Variable                    Type       Description\n",
    "# Grantmaker_name             String     Corporation/foundation that gave grant\n",
    "# Year                        Int        Year grant was given\n",
    "# Recipient_name              String     Organization that recived grant\n",
    "# NTEE_code                   String     NTEE code of organization given grant\n",
    "# NTEE_category               String     Broader category of organization according to IRS\n",
    "# Grant Amount                Float      Grant amount adjusted for inflation to 2020 dollars\n",
    "# Recipient_city              String     City of recipient organization\n",
    "# Recipient_state             String     State of recipient organization\n",
    "\n",
    "\n",
    "# text_df data dictionary\n",
    "# Variable                    Type       Description\n",
    "# Group                       String     Name of environmental nonprofit\n",
    "# Individualism               Float      Measure of prevalence of this discourse of delay (DoD) in the text\n",
    "# The 'free rider' excuse     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Whataboutism                Float      Measure of prevalence of this DoD in the text in given year\n",
    "# All talk, little action     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Fossil fuel solutionism     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# No sticks, just carrots     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Technological optimism      Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Appeal to well-being        Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Policy perfectionism        Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Appeal to social justice    Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Change is impossible        Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Doomism                     Float      Measure of prevalence of this DoD in the text in given year\n",
    "# Year                        Int        Year associated with prevalence measure\n",
    "# AF_indc                     Int        Indicator variable for American Forests (AF)\n",
    "# NFWF_indc                   Int        Indicator variable for the National Fish and Wildlife Foundation (NFWF)\n",
    "# NRDC_indc                   Int        Indicator variable for the Natural Resources Defense Council (NRDC)\n",
    "# CI_indc                     Int        Indicator variable for Conservation International(CI)\n",
    "# WWF_indc                    Int        Indicator variable for the World Wildlife Fund (WWF)\n",
    "# SC_indc                     Int        Indicator variable for the Sierra Club (SC)\n",
    "# OC_indc                     Int        Indicator variable for The Ocean Conservancy (OC)\n",
    "# EDF_indc                    Int        Indicator variable for the Environmental Defense Fund (EDF)\n",
    "# NAS_indc                    Int        Indicator variable for the National Audubon Society (NAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d4ccb936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/finnianlowden/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Imports\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Lasso, LassoCV\n",
    "from sklearn.linear_model import Ridge, RidgeCV\n",
    "from sklearn.preprocessing import normalize\n",
    "import scipy.cluster.hierarchy as shc\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Importing stop words (e.g., the, and, a, of, etc.)\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c46f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Importing data\n",
    "\n",
    "# Corporate giving dataset\n",
    "# The dataset is large, so it takes a little while\n",
    "complete_donations_df = pd.read_excel(\"Oil_corporations_NTEE_Data_MASTER_SHEET.xlsx\", sheet_name = \"Individual_donations\")\n",
    "\n",
    "# Text analysis results dataset\n",
    "complete_text_df = pd.read_excel(\"DoD_results.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "b659f014",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Formatting dataframes\n",
    "\n",
    "# Working with corporate philanthropy data\n",
    "# Dropping irrelevant columns (those not in data dictionary)\n",
    "donations_df = complete_donations_df[[\"grantmaker_name\", \"year\", \"recipient_name\", \"NTEE_code\",\n",
    "                                      \"NTEE_category\", \"Grant Amount (2020 Dollars)\",\n",
    "                                      \"recipient_city\", \"recipient_state\"]]\n",
    "\n",
    "# Renaming Grant Amount (2020 Dollars) to not include spaces & converting to int\n",
    "donations_df = donations_df.rename(columns = {\"Grant Amount (2020 Dollars)\": \"grant_amount\"})\n",
    "donations_df[\"grant_amount\"] = donations_df[\"grant_amount\"]\n",
    "\n",
    "# Making copy of complete_text_df\n",
    "text_df = complete_text_df.copy()\n",
    "\n",
    "# Checking to make sure changes were made\n",
    "# donations_df.head()\n",
    "# text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "e8cbd25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding corporate giving amount for each nonprofit to text_df\n",
    "reduce_donations_df = donations_df.copy()\n",
    "group_list = ['nature conservancy', 'american forests', 'national fish and wildlife foundation',\n",
    " 'natural resources defense council', 'conservation international', 'world wildlife fund',\n",
    " 'sierra club', 'ocean conservancy', 'environmental defense fund', 'audubon society']\n",
    "reduce_donations_df[\"recipient_name\"] = reduce_donations_df[\"recipient_name\"].str.lower()\n",
    "boolean_series = reduce_donations_df[\"recipient_name\"].isin(group_list)\n",
    "reduce_donations_df = reduce_donations_df[boolean_series]\n",
    "\n",
    "# Grouping by year and group\n",
    "annualized_donations_df = reduce_donations_df.groupby(\n",
    "    ['recipient_name', 'year'], as_index = False).agg({'grant_amount': sum})\n",
    "annualized_donations_df = pd.DataFrame(annualized_donations_df)\n",
    "# annualized_donations_df.to_excel(\"Output.xlsx\", index = False) # code to download as XSLX\n",
    "\n",
    "# Adding corporate giving to regression_df\n",
    "annualized_donations_df = annualized_donations_df.rename(\n",
    "    columns = {\"recipient_name\": \"Group\", \"year\": \"Year\"}) # Renaming group column\n",
    "text_df[\"Group\"] = text_df[\"Group\"].str.lower()\n",
    "regression_df = pd.merge(text_df, annualized_donations_df, on = ['Group', 'Year'], how = 'outer')\n",
    "regression_df[\"grant_amount\"] = regression_df[\"grant_amount\"].fillna(999)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7c801263",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Formatting control data in regression_df\n",
    "control_prevalence_df = text_df.copy()\n",
    "control_list = ['greenpeace', 'earthjustice']\n",
    "control_prevalence_df[\"Group\"] = control_prevalence_df[\"Group\"].str.lower()\n",
    "boolean_series = control_prevalence_df[\"Group\"].isin(control_list)\n",
    "control_prevalence_df = control_prevalence_df[boolean_series]\n",
    "\n",
    "# Grouping prevalence by year\n",
    "annualized_control_prevalence_df = control_prevalence_df.groupby(\n",
    "    ['Year'], as_index = False).agg({\"Individualism\": 'mean', \"The 'free rider' excuse\": 'mean',\n",
    "                                     \"Whataboutism\": 'mean', \"All talk, little action\": 'mean',\n",
    "                                     \"Fossil fuel solutionism\": 'mean', \"No sticks, just carrots\": 'mean',\n",
    "                                     \"Technological optimism\": 'mean', \"Appeal to well-being\": 'mean',\n",
    "                                     \"Policy perfectionism\": 'mean', \"Appeal to social justice\": 'mean',\n",
    "                                     \"Change is impossible\": 'mean', \"Doomism\": 'mean'})\n",
    "annualized_control_prevalence_df = pd.DataFrame(annualized_control_prevalence_df)\n",
    "annualized_control_prevalence_df = annualized_control_prevalence_df.rename(\n",
    "    columns={\"Individualism\": 'Individualism_control', \"The 'free rider' excuse\": 'Free_rider_control',\n",
    "             \"Whataboutism\": 'Whataboutism_control', \"All talk, little action\": 'Talk_no_action_control',\n",
    "             \"Fossil fuel solutionism\": 'FF_solutionism_control', \"No sticks, just carrots\": 'Carrots_control',\n",
    "             \"Technological optimism\": 'Tech_optimism_control', \"Appeal to well-being\": 'Well_being_control',\n",
    "             \"Policy perfectionism\": 'Perfect_policy_control', \"Appeal to social justice\": 'Social_justice_control',\n",
    "             \"Change is impossible\": 'Change_impossible_control', \"Doomism\": 'Doomism_control'})\n",
    "\n",
    "# Adding control data to regression_df\n",
    "annualized_control_prevalence_df = annualized_control_prevalence_df.fillna(999)\n",
    "regression_df = pd.merge(regression_df, annualized_control_prevalence_df, on = ['Year'], how = 'outer')\n",
    "\n",
    "# Checking to make sure changes were made\n",
    "# regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "33b97e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Adding indicator variables for each group\n",
    "# text_df['TNC'] = np.where(text_df['Group'] == 'Nature Conservancy', 1, 0) # Not including to avoid perfect multico\n",
    "regression_df['AF_indc'] = np.where(regression_df['Group'] == 'american forests', 1, 0)\n",
    "regression_df['NFWF_indc'] = np.where(regression_df['Group'] == 'national fish and wildlife foundation', 1, 0)\n",
    "regression_df['NRDC_indc'] = np.where(regression_df['Group'] == 'natural resources defense council', 1, 0)\n",
    "regression_df['CI_indc'] = np.where(regression_df['Group'] == 'conservation international', 1, 0)\n",
    "regression_df['WWF_indc'] = np.where(regression_df['Group'] == 'world wildlife fund', 1, 0)\n",
    "regression_df['SC_indc'] = np.where(regression_df['Group'] == 'sierra club', 1, 0)\n",
    "regression_df['OC_indc'] = np.where(regression_df['Group'] == 'ocean conservancy', 1, 0)\n",
    "regression_df['EDF_indc'] = np.where(regression_df['Group'] == 'environmental defense fund', 1, 0)\n",
    "regression_df['NAS_indc'] = np.where(regression_df['Group'] == 'audubon society', 1, 0)\n",
    "\n",
    "# Checking to make sure changes were made\n",
    "# regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "0f35e73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Renaming columns in regression_df\n",
    "regression_df = regression_df.rename(columns={\"The 'free rider' excuse\": 'Free_rider',\n",
    "             \"All talk, little action\": 'Talk_no_action', \"Fossil fuel solutionism\": 'FF_solutionism',\n",
    "             \"No sticks, just carrots\": 'Carrots', \"Technological optimism\": 'Tech_optimism',\n",
    "             \"Appeal to well-being\": 'Well_being', \"Policy perfectionism\": 'Perfect_policy',\n",
    "             \"Appeal to social justice\": 'Social_justice', \"Change is impossible\": 'Change_impossible'})\n",
    "                                              \n",
    "# Checking to make sure changes were made\n",
    "# regression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "20462583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>Individualism</th>\n",
       "      <th>Year</th>\n",
       "      <th>grant_amount</th>\n",
       "      <th>Individualism_control</th>\n",
       "      <th>AF_indc</th>\n",
       "      <th>NFWF_indc</th>\n",
       "      <th>NRDC_indc</th>\n",
       "      <th>CI_indc</th>\n",
       "      <th>WWF_indc</th>\n",
       "      <th>SC_indc</th>\n",
       "      <th>OC_indc</th>\n",
       "      <th>EDF_indc</th>\n",
       "      <th>NAS_indc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Group, Individualism, Year, grant_amount, Individualism_control, AF_indc, NFWF_indc, NRDC_indc, CI_indc, WWF_indc, SC_indc, OC_indc, EDF_indc, NAS_indc]\n",
       "Index: []"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Regression work\n",
    "y_list = ['Individualism', 'Free_rider', 'Whataboutism', 'Talk_no_action', 'FF_solutionism',\n",
    "'Carrots', 'Tech_optimism', 'Well_being', 'Perfect_policy', 'Social_justice',\n",
    "'Change_impossible', 'Doomism']\n",
    "\n",
    "control_list = [x + \"_control\" for x in y_list]\n",
    "\n",
    "current_y = 'Individualism' # Select whatever Y I want to see (e.g., Individualism prevalence)\n",
    "# Selecting y and dropping irrelevant ys and controls\n",
    "current_control = current_y + \"_control\"\n",
    "y_list.remove(current_y)\n",
    "control_list.remove(current_control)\n",
    "y_list = y_list + control_list\n",
    "\n",
    "# Creating X and Y data from regression_df\n",
    "y = regression_df[current_y]\n",
    "X = regression_df.drop(columns = y_list, axis=1)\n",
    "\n",
    "# Making sure all non-numeric columns and NaN values have been dropped\n",
    "# X.replace([np.inf, -np.inf], np.nan, inplace = True)\n",
    "# X.dropna(inplace = True)\n",
    "\n",
    "# Running OLS regressions\n",
    "olsReg = sm.OLS(y, X).fit()\n",
    "print(olsReg.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "547a8164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              var       val_ols\n",
      "0   Individualism  1.000000e+00\n",
      "1            Year  8.673617e-17\n",
      "2         AF_indc  8.881784e-14\n",
      "3       NFWF_indc  7.993606e-14\n",
      "4       NRDC_indc  8.171241e-14\n",
      "5         CI_indc  6.394885e-14\n",
      "6        WWF_indc  1.101341e-13\n",
      "7         SC_indc -6.394885e-14\n",
      "8         OC_indc  4.263256e-14\n",
      "9        EDF_indc  4.263256e-14\n",
      "10       NAS_indc  8.526513e-14\n"
     ]
    }
   ],
   "source": [
    "# Printing resuls from LASSO reg\n",
    "coef_comp = pd.DataFrame({'var': X.columns, 'val_ols': olsReg.params.tolist()})\n",
    "print(coef_comp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5bdb56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
